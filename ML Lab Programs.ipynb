{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1b23b9",
   "metadata": {},
   "source": [
    "# Lab Program 1\n",
    "## Implement and demonstratetheFIND-Salgorithm for finding the most specific hypothesis based on a given set of training data samples. Read the training data from a .CSV file and show the output for test cases. Develop an interactive program by Compareing the result by implementing LIST THEN ELIMINATE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3d9e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sunny' 'Warm' '?' 'Strong' '?' '?']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('finds1.csv')\n",
    "def train(concepts, target):\n",
    "    for i, val in enumerate(target):\n",
    "        if val == \"Yes\":\n",
    "            specific_h = concepts[i]\n",
    "            break\n",
    "    for i,h in enumerate(concepts):\n",
    "        if target[i] == \"Yes\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] == specific_h[x]:\n",
    "                    pass\n",
    "                else:\n",
    "                    specific_h[x] = \"?\"\n",
    "    return specific_h\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print(train(concepts,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69230bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific hypothesis obtained by LIST THEN ELIMINATE algorithm:\n",
      "['Sunny' 'Warm' '?' 'Strong' '?' '?']\n",
      "\n",
      "Specific hypothesis obtained by the original code:\n",
      "['Sunny' 'Warm' 'Normal' 'Strong' 'Warm' 'Same']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('finds1.csv')\n",
    "def list_then_eliminate(concepts, target):\n",
    "    positive_examples = concepts[target == 'Yes']\n",
    "    specific_hypothesis = positive_examples[0].copy()\n",
    "    for example in positive_examples[1:]:\n",
    "        for i, attribute in enumerate(example):\n",
    "            if attribute != specific_hypothesis[i]:\n",
    "                specific_hypothesis[i] = '?'\n",
    "    return specific_hypothesis\n",
    "def train(concepts, target):\n",
    "    for i, val in enumerate(target):\n",
    "        if val == \"Yes\":\n",
    "            specific_h = concepts[i]\n",
    "            break\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == \"Yes\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] == specific_h[x]:\n",
    "                    pass\n",
    "                else:\n",
    "                    specific_h[x] = \"?\"\n",
    "        return specific_h\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print('Specific hypothesis obtained by LIST THEN ELIMINATE algorithm:')\n",
    "print(list_then_eliminate(concepts, target))\n",
    "print('\\nSpecific hypothesis obtained by the original code:')\n",
    "print(train(concepts, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06ace5",
   "metadata": {},
   "source": [
    "# Lab Program 2\n",
    "## For a given set of training data examples stored in a .CSV file, implement and demonstrate the Candidate-Eliminationalgorithm. Output a description of the set of all hypotheses consistent with the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbea3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final S:\n",
      "['Sunny' 'Warm' '?' 'Strong' '?' '?']\n",
      "Final G:\n",
      "[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sky</th>\n",
       "      <th>Airtemp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Water</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>WaterSport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Same</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Warm</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Same</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cold</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Change</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Warm</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Change</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sky Airtemp Humidity    Wind Water Forecast WaterSport\n",
       "0   Sunny    Warm   Normal  Strong  Warm     Same        Yes\n",
       "1   Sunny    Warm     High  Strong  Warm     Same        Yes\n",
       "2  Cloudy    Cold     High  Strong  Warm   Change         No\n",
       "3   Sunny    Warm     High  Strong  Cool   Change        Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data=pd.read_csv('finds1.csv'))\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "target = np.array(data.iloc[:,-1])\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == \"Yes\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "        if target[i] == \"No\":\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "    indices = [i for i,val in enumerate(general_h) if val == ['?','?','?','?','?','?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?','?','?','?','?','?'])\n",
    "    return specific_h, general_h\n",
    "s_final, g_final = learn(concepts, target)\n",
    "print(\"Final S:\", s_final, sep=\"\\n\")\n",
    "print(\"Final G:\", g_final, sep=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572dbfa",
   "metadata": {},
   "source": [
    "# Lab Program 3\n",
    "## Demonstrate Pre processing (Data Cleaning, Integration and Transformation) activity on suitable data:\n",
    "### For example:\n",
    "### Identify and Delete Rows that Contain Duplicate Data by considering an appropriate dataset.\n",
    "### Identify and Delete Columns That Contain a Single Value by considering an appropriate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1aa25f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates in dataset 1:\n",
      "   A  B\n",
      "0  1  5\n",
      "1  2  6\n",
      "2  2  6\n",
      "3  3  7\n",
      "4  4  8\n",
      "5  5  9\n",
      "6  5  9\n",
      "\n",
      "After removing duplicates in dataset 1:\n",
      "   A  B\n",
      "0  1  5\n",
      "1  2  6\n",
      "3  3  7\n",
      "4  4  8\n",
      "5  5  9\n",
      "\n",
      "Before removing single value columns in dataset 2:\n",
      "    C   D\n",
      "0  10  11\n",
      "1  10  12\n",
      "2  10  13\n",
      "3  10  14\n",
      "4  10  15\n",
      "\n",
      "After removing single value columns in dataset 2:\n",
      "    D\n",
      "0  11\n",
      "1  12\n",
      "2  13\n",
      "3  14\n",
      "4  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = {'A': [1, 2, 2, 3, 4, 5, 5],\n",
    "         'B': [5, 6, 6, 7, 8, 9, 9]}\n",
    "data2 = {'C': [10, 10, 10, 10, 10],\n",
    "         'D': [11, 12, 13, 14, 15]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"Before removing duplicates in dataset 1:\")\n",
    "print(df1)\n",
    "df1.drop_duplicates(inplace=True)\n",
    "print(\"\\nAfter removing duplicates in dataset 1:\")\n",
    "print(df1)\n",
    "print(\"\\nBefore removing single value columns in dataset 2:\")\n",
    "print(df2)\n",
    "cols_to_remove = [col for col in df2.columns if df2[col].nunique() <= 1]\n",
    "df2.drop(cols_to_remove, axis=1, inplace=True)\n",
    "print(\"\\nAfter removing single value columns in dataset 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b18943",
   "metadata": {},
   "source": [
    "# Lab Program 4\n",
    "## Demonstrate the working of the decision tree based ID3 algorithm. Use an appropriate data set for building the decision tree and apply this knowledge toclassify a new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa3908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box, fontname=\"helvetica\"] ;\n",
      "edge [fontname=\"helvetica\"] ;\n",
      "0 [label=\"Outlook_overcast <= 0.5\\nentropy = 0.94\\nsamples = 14\\nvalue = [5, 9]\"] ;\n",
      "1 [label=\"Humidity_normal <= 0.5\\nentropy = 1.0\\nsamples = 10\\nvalue = [5, 5]\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"Outlook_sunny <= 0.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"Windy <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=\"entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]\"] ;\n",
      "3 -> 5 ;\n",
      "6 [label=\"entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]\"] ;\n",
      "2 -> 6 ;\n",
      "7 [label=\"Windy <= 0.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]\"] ;\n",
      "1 -> 7 ;\n",
      "8 [label=\"entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]\"] ;\n",
      "7 -> 8 ;\n",
      "9 [label=\"Outlook_rainy <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]\"] ;\n",
      "7 -> 9 ;\n",
      "10 [label=\"entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]\"] ;\n",
      "9 -> 10 ;\n",
      "11 [label=\"entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]\"] ;\n",
      "9 -> 11 ;\n",
      "12 [label=\"entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]\"] ;\n",
      "0 -> 12 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "data = pd.read_csv(\"weather.csv\")\n",
    "X = data.drop('Play', axis=1)\n",
    "y = data['Play']\n",
    "X = pd.get_dummies(X)\n",
    "y = y.map({'yes': 1, 'no': 0})\n",
    "classifier = DecisionTreeClassifier(criterion='entropy')\n",
    "classifier.fit(X, y)\n",
    "export_graphviz(classifier, out_file='tree.dot', feature_names=X.columns)\n",
    "\n",
    "with open('tree.dot', 'r') as file:\n",
    "    tree_data = file.read()\n",
    "print(tree_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2816f35",
   "metadata": {},
   "source": [
    "# Lab Program 5\n",
    "## Demonstrate the working of the Random forest algorithm. Use an appropriate data set for building and apply this knowledge toclassify a new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebfad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Predicted class of new sample:  [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "new_sample = [[3, 5, 4, 2]]\n",
    "new_pred = clf.predict(new_sample)\n",
    "print(\"Predicted class of new sample: \", new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e19e9",
   "metadata": {},
   "source": [
    "# Lab Program 6\n",
    "## Implement the na√Øve Bayesian classifier for a sample training data set stored as a .CSV file. Compute the accuracy of the classifier, considering few test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ae4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy on new data set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test_data should contain all possible outputs values that can be given to any attribute\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def gaussian_naive_bayes(data, test_data):\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    X = pd.get_dummies(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    y_pred_new = nb.predict(pd.get_dummies(test_data.iloc[:, :-1]))\n",
    "    accuracy_new = accuracy_score(test_data.iloc[:, -1], y_pred_new)\n",
    "\n",
    "    print(\"Accuracy on new data set:\", accuracy_new)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"test_data.csv\")\n",
    "    test_data = pd.read_csv(\"test_data.csv\")\n",
    "    gaussian_naive_bayes(data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf0e87",
   "metadata": {},
   "source": [
    "# Lab Program 7\n",
    "## Assuming a set of documents that need to be classified, use the naive Bayesian Classifier model to perform this task. Calculate the accuracy, precision, and recall for your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5209fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7728359001593202\n",
      "Precision: 0.7616683207318354\n",
      "Recall: 0.7728359001593202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecc985",
   "metadata": {},
   "source": [
    "### Lab Program 8\n",
    "## Construct a Bayesian network considering medical data. Use this model to demonstrate the diagnosis of heart patients using standard Heart Disease Data Set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9bea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Enter Age: 1\n",
      "Enter Gender: 0\n",
      "Enter FamilyHistory: 0\n",
      "Enter dietEnum: 1\n",
      "Enter LifeStyle: 3\n",
      "Enter Cholesterol: 0\n",
      "Probability(HeartDisease) = 0.5\n",
      "Enter for Continue: 0, Exit: 1 1\n"
     ]
    }
   ],
   "source": [
    "import bayespy as bp\n",
    "import numpy as np\n",
    "import csv\n",
    "from colorama import init, Fore, Back, Style\n",
    "\n",
    "init()\n",
    "\n",
    "ageEnum = {'SuperSeniorCitizen': 0, 'SeniorCitizen': 1, 'MiddleAged': 2, 'Youth': 3, 'Teen': 4}\n",
    "genderEnum = {'Male': 0, 'Female': 1}\n",
    "familyHistoryEnum = {'Yes': 0, 'No': 1}\n",
    "dietEnum = {'High': 0, 'Medium': 1, 'Low': 2}\n",
    "lifeStyleEnum = {'Athlete': 0, 'Active': 1, 'Moderate': 2, 'Sedetary': 3}\n",
    "cholesterolEnum = {'High': 0, 'BorderLine': 1, 'Normal': 2}\n",
    "heartDiseaseEnum = {'Yes': 0, 'No': 1}\n",
    "\n",
    "with open('heart_disease_data.csv') as csvfile:\n",
    "    lines = csv.reader(csvfile)\n",
    "    dataset = list(lines)\n",
    "    data = []\n",
    "    for x in dataset:\n",
    "        data.append([\n",
    "            ageEnum[x[0]],\n",
    "            genderEnum[x[1]],\n",
    "            familyHistoryEnum[x[2]],\n",
    "            dietEnum[x[3]],\n",
    "            lifeStyleEnum[x[4]],\n",
    "            cholesterolEnum[x[5]],\n",
    "            heartDiseaseEnum[x[6]]\n",
    "        ])\n",
    "data = np.array(data)\n",
    "N = len(data)\n",
    "\n",
    "p_age = bp.nodes.Dirichlet(1.0 * np.ones(5))\n",
    "age = bp.nodes.Categorical(p_age, plates=(N,))\n",
    "age.observe(data[:, 0])\n",
    "\n",
    "p_gender = bp.nodes.Dirichlet(1.0 * np.ones(2))\n",
    "gender = bp.nodes.Categorical(p_gender, plates=(N,))\n",
    "gender.observe(data[:, 1])\n",
    "\n",
    "p_familyhistory = bp.nodes.Dirichlet(1.0 * np.ones(2))\n",
    "familyhistory = bp.nodes.Categorical(p_familyhistory, plates=(N,))\n",
    "familyhistory.observe(data[:, 2])\n",
    "\n",
    "p_diet = bp.nodes.Dirichlet(1.0 * np.ones(3))\n",
    "diet = bp.nodes.Categorical(p_diet, plates=(N,))\n",
    "diet.observe(data[:, 3])\n",
    "\n",
    "p_lifestyle = bp.nodes.Dirichlet(1.0 * np.ones(4))\n",
    "lifestyle = bp.nodes.Categorical(p_lifestyle, plates=(N,))\n",
    "lifestyle.observe(data[:, 4])\n",
    "\n",
    "p_cholesterol = bp.nodes.Dirichlet(1.0 * np.ones(3))\n",
    "cholesterol = bp.nodes.Categorical(p_cholesterol, plates=(N,))\n",
    "cholesterol.observe(data[:, 5])\n",
    "\n",
    "p_heartdisease = bp.nodes.Dirichlet(np.ones(2), plates=(5, 2, 2, 3, 4, 3))\n",
    "heartdisease = bp.nodes.MultiMixture([age, gender, familyhistory, diet, lifestyle, cholesterol], \n",
    "                                     bp.nodes.Categorical,p_heartdisease)\n",
    "\n",
    "heartdisease.observe(data[:, 6])\n",
    "p_heartdisease.update()\n",
    "\n",
    "m = 0\n",
    "while m == 0:\n",
    "    print(\"\\n\")\n",
    "    res = bp.nodes.MultiMixture(\n",
    "        [int(input('Enter Age: ')),\n",
    "         int(input('Enter Gender: ')),\n",
    "         int(input('Enter FamilyHistory: ')),\n",
    "         int(input('Enter dietEnum: ')),\n",
    "         int(input('Enter LifeStyle: ')),\n",
    "         int(input('Enter Cholesterol: '))],\n",
    "        bp.nodes.Categorical,\n",
    "        p_heartdisease\n",
    "    ).get_moments()[0][heartDiseaseEnum['Yes']]\n",
    "    print(\"Probability(HeartDisease) = \" + str(res))\n",
    "    m = int(input(\"Enter for Continue: 0, Exit: 1 \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c949688",
   "metadata": {},
   "source": [
    "# Lab Program 9\n",
    "## Demonstrate the working of EM algorithm to cluster a set of data stored in a .CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4491be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels:\n",
      "[1 1 0 1 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.values\n",
    "num_clusters = 3\n",
    "gmm = GaussianMixture(n_components=num_clusters)\n",
    "gmm.fit(X)\n",
    "labels = gmm.predict(X)\n",
    "print('Cluster Labels:')\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5245c",
   "metadata": {},
   "source": [
    "# Lab Program 10\n",
    "## Demonstrate the working of SVM classifier for a suitable data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d16c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0d1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
